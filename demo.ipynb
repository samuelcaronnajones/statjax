{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks through the core functionality of the package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics and OLS\n",
    "\n",
    "To begin, let's load the Longly dataset from Statsmodels. Statjax follows the Scikit-Learn convention of `model().fit(X,y)` rather than the Statsmodels convention of `model(y,X).fit()`. Models can take dataframe, array, or model matrix (see below) inputs. They will add intercepts unless `add_intercept = False` is passed in fit. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statjax as sj\n",
    "\n",
    "\n",
    "longley = sm.datasets.longley.load_pandas()\n",
    "X = longley.exog\n",
    "y = longley.endog\n",
    "\n",
    "ols= sj.OLS().fit(X, y)\n",
    "ols_no_intercept= sj.OLS().fit(X, y, add_intercept=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OLS model supports non-robust, heteroskedasticity-robust, and clustered standard errors following [Cameron and Miller (2015)](https://cameron.econ.ucdavis.edu/research/Cameron_Miller_JHR_2015_February.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_robust = sj.OLS(\"robust\").fit(X,y,)\n",
    "decade = X[\"YEAR\"] // 10\n",
    "ols_clustered = sj.OLS(\"clustered\").fit(X, y, decade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize, use the table functionality, which closely follows the Python Stargazer package â€“ see their documentation for table options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "OLS regressions<br><table style=\"text-align:center\"><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(TOTEMP)</td><td>(TOTEMP)</td><td>(TOTEMP)</td><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">OLS</td><td colspan=\"1\">OLS (robust)</td><td colspan=\"1\">OLS (clustered)</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>-3482258.637<sup>***</sup></td><td>-3482258.637<sup>***</sup></td><td>-3482258.637<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(4.69e-03)</td><td>(6.08e-03)</td><td>(1.38e-03)</td></tr>\n",
       "<tr><td style=\"text-align:left\">GNPDEFL</td><td>15.062<sup></sup></td><td>15.062<sup></sup></td><td>15.062<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(83.113)</td><td>(87.551)</td><td>(45.657)</td></tr>\n",
       "<tr><td style=\"text-align:left\">GNP</td><td>-0.036<sup>*</sup></td><td>-0.036<sup></sup></td><td>-0.036<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.019)</td><td>(0.022)</td><td>(6.48e-03)</td></tr>\n",
       "<tr><td style=\"text-align:left\">UNEMP</td><td>-2.020<sup>***</sup></td><td>-2.020<sup>***</sup></td><td>-2.020<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.268)</td><td>(0.300)</td><td>(0.073)</td></tr>\n",
       "<tr><td style=\"text-align:left\">ARMED</td><td>-1.033<sup>***</sup></td><td>-1.033<sup>***</sup></td><td>-1.033<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.179)</td><td>(0.110)</td><td>(0.063)</td></tr>\n",
       "<tr><td style=\"text-align:left\">POP</td><td>-0.051<sup></sup></td><td>-0.051<sup></sup></td><td>-0.051<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.206)</td><td>(0.261)</td><td>(0.057)</td></tr>\n",
       "<tr><td style=\"text-align:left\">YEAR</td><td>1829.151<sup>***</sup></td><td>1829.151<sup>***</sup></td><td>1829.151<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(11.349)</td><td>(13.869)</td><td>(3.011)</td></tr>\n",
       "\n",
       "<td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>16</td><td>16</td><td>16</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.995</td><td>0.995</td><td>0.995</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>251.646<sup>***</sup> (df=15; 10)</td><td>251.646<sup>***</sup> (df=15; 10)</td><td>251.646<sup>***</sup> (df=15; 10)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"3\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x28794e060>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ols_table = sj.RegressionTable([ols , ols_robust, ols_clustered])\n",
    "ols_table.custom_columns([\"OLS\", \"OLS (robust)\", \"OLS (clustered)\"])\n",
    "ols_table.title(\"OLS regressions\")\n",
    "display(ols_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tables can be converted to latex for display, which additionally cleans up the dependent variable row - see demo_table.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{@{\\extracolsep{5pt}}lccc}\n",
      "\\\\[-1.8ex]\\hline\n",
      "\\hline \\\\[-1.8ex]\n",
      "\\textit{Dependent variable: } &  \\multicolumn{3}{c}{TOTEMP} \n",
      "% \\\\[-1.8ex]\n",
      "\\cr \\cline{2-4}\n",
      "\\\\[-1.8ex]\\\\[-1.8ex] & \\multicolumn{1}{c}{OLS} & \\multicolumn{1}{c}{OLS (robust)} & \\multicolumn{1}{c}{OLS (clustered)}  \\\\\n",
      "\\\\[-1.8ex] & (1) & (2) & (3) \\\\\n",
      "\\hline \\\\[-1.8ex]\n",
      " Intercept & -3482258.637$^{***}$ & -3482258.637$^{***}$ & -3482258.637$^{***}$ \\\\\n",
      "& (4.69e-03) & (6.08e-03) & (1.38e-03) \\\\\n",
      " GNPDEFL & 15.062$^{}$ & 15.062$^{}$ & 15.062$^{}$ \\\\\n",
      "& (83.113) & (87.551) & (45.657) \\\\\n",
      " GNP & -0.036$^{*}$ & -0.036$^{}$ & -0.036$^{***}$ \\\\\n",
      "& (0.019) & (0.022) & (6.48e-03) \\\\\n",
      " UNEMP & -2.020$^{***}$ & -2.020$^{***}$ & -2.020$^{***}$ \\\\\n",
      "& (0.268) & (0.300) & (0.073) \\\\\n",
      " ARMED & -1.033$^{***}$ & -1.033$^{***}$ & -1.033$^{***}$ \\\\\n",
      "& (0.179) & (0.110) & (0.063) \\\\\n",
      " POP & -0.051$^{}$ & -0.051$^{}$ & -0.051$^{}$ \\\\\n",
      "& (0.206) & (0.261) & (0.057) \\\\\n",
      " YEAR & 1829.151$^{***}$ & 1829.151$^{***}$ & 1829.151$^{***}$ \\\\\n",
      "& (11.349) & (13.869) & (3.011) \\\\\n",
      "\\hline \\\\[-1.8ex]\n",
      " Observations & 16 & 16 & 16 \\\\\n",
      " $R^2$ & 0.995 & 0.995 & 0.995 \\\\\n",
      " F Statistic & 251.646$^{***}$ (df=15; 10) & 251.646$^{***}$ (df=15; 10) & 251.646$^{***}$ (df=15; 10) \\\\\n",
      "\\hline\n",
      "\\hline \\\\[-1.8ex]\n",
      "\\textit{Note:} & \\multicolumn{3}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print(ols_table.render_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table is also used by the `.summary()` method shared by all linear models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(TOTEMP)</td><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td></tr>\n",
       "<tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>-3482258.637<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(4.69e-03)</td></tr>\n",
       "<tr><td style=\"text-align:left\">GNPDEFL</td><td>15.062<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(83.113)</td></tr>\n",
       "<tr><td style=\"text-align:left\">GNP</td><td>-0.036<sup>*</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.019)</td></tr>\n",
       "<tr><td style=\"text-align:left\">UNEMP</td><td>-2.020<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.268)</td></tr>\n",
       "<tr><td style=\"text-align:left\">ARMED</td><td>-1.033<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.179)</td></tr>\n",
       "<tr><td style=\"text-align:left\">POP</td><td>-0.051<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.206)</td></tr>\n",
       "<tr><td style=\"text-align:left\">YEAR</td><td>1829.151<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(11.349)</td></tr>\n",
       "\n",
       "<td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>16</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.995</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>251.646<sup>***</sup> (df=15; 10)</td></tr>\n",
       "<tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"1\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x2866a6b70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RegressionTable` can take either a single model or a list of models. If arrays are passed, the table will substitute variable names. The table will produce rows for all variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(TOTEMP)</td><td>(y)</td><td>(TOTEMP)</td><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>-3482258.637<sup>***</sup></td><td>-3482258.637<sup>***</sup></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(4.69e-03)</td><td>(4.69e-03)</td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">GNPDEFL</td><td>15.062<sup></sup></td><td></td><td>-52.994<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(83.113)</td><td></td><td>(129.545)</td></tr>\n",
       "<tr><td style=\"text-align:left\">GNP</td><td>-0.036<sup>*</sup></td><td></td><td>0.071<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.019)</td><td></td><td>(0.030)</td></tr>\n",
       "<tr><td style=\"text-align:left\">UNEMP</td><td>-2.020<sup>***</sup></td><td></td><td>-0.423<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.268)</td><td></td><td>(0.418)</td></tr>\n",
       "<tr><td style=\"text-align:left\">ARMED</td><td>-1.033<sup>***</sup></td><td></td><td>-0.573<sup>*</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.179)</td><td></td><td>(0.279)</td></tr>\n",
       "<tr><td style=\"text-align:left\">POP</td><td>-0.051<sup></sup></td><td></td><td>-0.414<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.206)</td><td></td><td>(0.321)</td></tr>\n",
       "<tr><td style=\"text-align:left\">YEAR</td><td>1829.151<sup>***</sup></td><td></td><td>48.418<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(11.349)</td><td></td><td>(17.689)</td></tr>\n",
       "<tr><td style=\"text-align:left\">x0</td><td></td><td>15.062<sup></sup></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(83.113)</td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">x1</td><td></td><td>-0.036<sup>*</sup></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.019)</td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">x2</td><td></td><td>-2.020<sup>***</sup></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.268)</td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">x3</td><td></td><td>-1.033<sup>***</sup></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.179)</td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">x4</td><td></td><td>-0.051<sup></sup></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.206)</td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">x5</td><td></td><td>1829.151<sup>***</sup></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(11.349)</td><td></td></tr>\n",
       "\n",
       "<td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>16</td><td>16</td><td>16</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.995</td><td>0.995</td><td>0.988</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>251.646<sup>***</sup> (df=15; 10)</td><td>251.646<sup>***</sup> (df=15; 10)</td><td>121.412<sup>***</sup> (df=15; 10)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"3\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x286364da0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_from_arrays = sj.OLS().fit(X.values, y.values)\n",
    "sj.RegressionTable([ols, ols_from_arrays,ols_no_intercept])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final input type supported is formulaic `model_matrix`. If a `model_matrix` is used to fit the model, the model spec of that data will be used to transform future inputs into predict.  The variable names will automatically export. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions are equal: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(TOTEMP)</td><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td></tr>\n",
       "<tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>49160.443<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.159)</td></tr>\n",
       "<tr><td style=\"text-align:left\">GNPDEFL</td><td>39.530<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(9.652)</td></tr>\n",
       "<tr><td style=\"text-align:left\">GNP</td><td>0.037<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(3.32e-03)</td></tr>\n",
       "<tr><td style=\"text-align:left\">ARMED:UNEMP</td><td>-2.59e-04<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(8.85e-05)</td></tr>\n",
       "\n",
       "<td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>16</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.980</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>135.290<sup>***</sup> (df=15; 13)</td></tr>\n",
       "<tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"1\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x293777110>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from formulaic import model_matrix\n",
    "\n",
    "y_f,X_f = model_matrix(\"TOTEMP ~ GNPDEFL + GNP + ARMED:UNEMP\", longley.data )\n",
    "\n",
    "formula_model = sj.OLS().fit(X_f, y_f, add_intercept=False)\n",
    "print(f\"predictions are equal: {bool((formula_model.predict(X_f)==formula_model.predict(longley.data)).prod())}\")\n",
    "formula_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " However, it will not predict for model matrices with different formulas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: ModelMatrix object has different model spec than fit spec. Either pass a ModelMatrix with the correct spec or a non-ModelMatrix object.\n"
     ]
    }
   ],
   "source": [
    "different_formula_X = model_matrix(\"GNPDEFL + GNP + ARMED*UNEMP\", longley.data)\n",
    "\n",
    "try:\n",
    "    different_formula_X = model_matrix(\"GNPDEFL + GNP + ARMED*UNEMP\", longley.data)\n",
    "    formula_model.predict(different_formula_X)\n",
    "except Exception as e:\n",
    "    print(f\"error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rounding out the core of the package is a simple ridge regression minimizing $\\mathbf X^\\top  \\beta - \\mathbf y + \\lambda \\beta^\\top \\beta $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(TOTEMP)</td><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td></tr>\n",
       "<tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>-0.385</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">GNPDEFL</td><td>-48.982</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">GNP</td><td>0.070</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">UNEMP</td><td>-0.433</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">ARMED</td><td>-0.575</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">POP</td><td>-0.407</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">YEAR</td><td>47.973</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td></tr>\n",
       "\n",
       "<td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>16</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.988</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>92.495<sup>***</sup> (df=15; 10)</td></tr>\n",
       "<tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"1\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x29584bf50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj.Ridge(1).fit(X,y).summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Linear Models\n",
    "\n",
    "All of the GLM implementations follow Agresti, Foundations of Linear and Generalized Linear Models (2015). The models use either Fisher scoring or iterative least squares to fit $\\beta$, then Newton-Raphson to fit any other parameters of the distribution. The Oryx library provides the infrastructure for random variables, and all GLMS are fitted with iteratively weighted least squares (IRLS).\n",
    "\n",
    "\n",
    "Normal, Bernoulli, Poisson, Gamma, and Inverse Normal GLMS are supported by default. Certain link functions can be imported from glm as `statjax.glm`, currently identity_link, log_link, inverse_link, logit_link, probit_link, and inverse_squared_link. \n",
    "\n",
    "Some canonical models are provided as default options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Base GLMS<br><table style=\"text-align:center\"><tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(YES)</td><td>(YES)</td><td>(YES)</td><td>(YES)</td><td>(YES)</td><td>(YES)</td><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">Normal</td><td colspan=\"1\">Poisson (Identity)</td><td colspan=\"1\">Poisson (Log)</td><td colspan=\"1\">Gamma</td><td colspan=\"1\">Inverse Gaussian</td><td colspan=\"1\">Inverse Gaussian (Identity)</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td><td>(5)</td><td>(6)</td></tr>\n",
       "<tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>137.414<sup>***</sup></td><td>129.525<sup></sup></td><td>5.779<sup>***</sup></td><td>0.018<sup>*</sup></td><td>5.36e-04<sup></sup></td><td>113.683<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(35.507)</td><td>(87.264)</td><td>(1.477)</td><td>(0.010)</td><td>(7.94e-04)</td><td>(164.364)</td></tr>\n",
       "<tr><td style=\"text-align:left\">COUTAX</td><td>-0.116<sup>**</sup></td><td>-0.109<sup></sup></td><td>-2.47e-03<sup></sup></td><td>-4.96e-05<sup>***</sup></td><td>-9.57e-07<sup></sup></td><td>-0.093<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.050)</td><td>(0.123)</td><td>(2.09e-03)</td><td>(1.42e-05)</td><td>(1.11e-06)</td><td>(0.231)</td></tr>\n",
       "<tr><td style=\"text-align:left\">UNEMPF</td><td>-5.186<sup>***</sup></td><td>-4.903<sup></sup></td><td>-0.105<sup></sup></td><td>-2.03e-03<sup>***</sup></td><td>-3.86e-05<sup></sup></td><td>-4.333<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(1.604)</td><td>(3.881)</td><td>(0.068)</td><td>(4.65e-04)</td><td>(3.71e-05)</td><td>(7.091)</td></tr>\n",
       "<tr><td style=\"text-align:left\">MOR</td><td>0.285<sup>***</sup></td><td>0.300<sup></sup></td><td>4.53e-03<sup></sup></td><td>7.18e-05<sup>***</sup></td><td>1.13e-06<sup></sup></td><td>0.327<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.085)</td><td>(0.210)</td><td>(3.52e-03)</td><td>(2.37e-05)</td><td>(1.85e-06)</td><td>(0.386)</td></tr>\n",
       "<tr><td style=\"text-align:left\">ACT</td><td>-0.420<sup>***</sup></td><td>-0.407<sup></sup></td><td>-6.86e-03<sup></sup></td><td>-1.12e-04<sup>***</sup></td><td>-1.82e-06<sup></sup></td><td>-0.382<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.137)</td><td>(0.350)</td><td>(5.47e-03)</td><td>(3.55e-05)</td><td>(2.67e-06)</td><td>(0.696)</td></tr>\n",
       "<tr><td style=\"text-align:left\">GDP</td><td>4.50e-04<sup></sup></td><td>4.39e-04<sup></sup></td><td>8.24e-06<sup></sup></td><td>1.47e-07<sup></sup></td><td>2.55e-09<sup></sup></td><td>4.15e-04<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(3.75e-04)</td><td>(9.06e-04)</td><td>(1.58e-05)</td><td>(1.08e-07)</td><td>(8.56e-09)</td><td>(1.61e-03)</td></tr>\n",
       "<tr><td style=\"text-align:left\">AGE</td><td>1.840<sup>**</sup></td><td>1.755<sup></sup></td><td>0.031<sup></sup></td><td>5.19e-04<sup>**</sup></td><td>8.62e-06<sup></sup></td><td>1.607<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.773)</td><td>(1.920)</td><td>(0.032)</td><td>(2.10e-04)</td><td>(1.61e-05)</td><td>(3.595)</td></tr>\n",
       "<tr><td style=\"text-align:left\">COUTAX_FEMALEUNEMP</td><td>5.89e-03<sup>**</sup></td><td>5.56e-03<sup></sup></td><td>1.22e-04<sup></sup></td><td>2.43e-06<sup>***</sup></td><td>4.66e-08<sup></sup></td><td>4.87e-03<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(2.26e-03)</td><td>(5.48e-03)</td><td>(9.52e-05)</td><td>(6.53e-07)</td><td>(5.19e-08)</td><td>(0.010)</td></tr>\n",
       "\n",
       "<td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>32</td><td>32</td><td>32</td><td>32</td><td>32</td><td>32</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.842</td><td>0.841</td><td>0.844</td><td>0.844</td><td>0.841</td><td>0.838</td></tr><tr><td style=\"text-align: left\">AIC</td><td>179.689</td><td>211.665</td><td>211.595</td><td>180.947</td><td>250.382</td><td>249.717</td></tr><tr><td style=\"text-align: left\">BIC</td><td>191.415</td><td>223.390</td><td>223.321</td><td>192.673</td><td>262.108</td><td>261.442</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>15.271<sup>***</sup> (df=31; 25)</td><td>15.219<sup>***</sup> (df=31; 25)</td><td>15.502<sup>***</sup> (df=31; 25)</td><td>15.509<sup>***</sup> (df=31; 25)</td><td>15.241<sup>***</sup> (df=31; 25)</td><td>14.842<sup>***</sup> (df=31; 25)</td></tr>\n",
       "<tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"6\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x295870e00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statjax.glm import PoissonGLM, GammaGLM, InverseNormalGLM, NormalGLM\n",
    "\n",
    "scotland =  sm.datasets.scotland.load()\n",
    "X = scotland.exog\n",
    "y = scotland.endog\n",
    "\n",
    "nglm = NormalGLM().fit(X,y) \n",
    "\n",
    "poisson_id = PoissonGLM(link=sj.glm.identity_link).fit(X,y, )\n",
    "poisson_log = PoissonGLM(link = sj.glm.log_link).fit(X,y)\n",
    "glm_gamma_new = GammaGLM().fit(X,y)\n",
    "inv_gauss = InverseNormalGLM().fit(X,y)\n",
    "inv_gauss2 = InverseNormalGLM(link = sj.glm.identity_link).fit(X,y)\n",
    "\n",
    "glm_table = sj.RegressionTable([nglm,poisson_id, poisson_log,glm_gamma_new,inv_gauss,inv_gauss2])\n",
    "glm_table.custom_columns([\"Normal\", \"Poisson (Identity)\", \"Poisson (Log)\", \"Gamma\", \"Inverse Gaussian\", \"Inverse Gaussian (Identity)\"])\n",
    "glm_table.title(\"Base GLMS\")\n",
    "glm_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GLM framework allows the definition of custom GLMs from a link function and distribution. For example, here's a custom Poisson model with root link compared to the canonical (and identity) links: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Poisson GLMs<br><table style=\"text-align:center\"><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(YES)</td><td>(YES)</td><td>(YES)</td><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">Root Poisson</td><td colspan=\"1\">Identity Poisson</td><td colspan=\"1\">Log Poisson</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>13.268<sup>**</sup></td><td>129.525<sup></sup></td><td>5.779<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(5.674)</td><td>(87.264)</td><td>(1.477)</td></tr>\n",
       "<tr><td style=\"text-align:left\">COUTAX</td><td>-8.35e-03<sup></sup></td><td>-0.109<sup></sup></td><td>-2.47e-03<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(8.04e-03)</td><td>(0.123)</td><td>(2.09e-03)</td></tr>\n",
       "<tr><td style=\"text-align:left\">UNEMPF</td><td>-0.362<sup></sup></td><td>-4.903<sup></sup></td><td>-0.105<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.256)</td><td>(3.881)</td><td>(0.068)</td></tr>\n",
       "<tr><td style=\"text-align:left\">MOR</td><td>0.018<sup></sup></td><td>0.300<sup></sup></td><td>4.53e-03<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.014)</td><td>(0.210)</td><td>(3.52e-03)</td></tr>\n",
       "<tr><td style=\"text-align:left\">ACT</td><td>-0.026<sup></sup></td><td>-0.407<sup></sup></td><td>-6.86e-03<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.022)</td><td>(0.350)</td><td>(5.47e-03)</td></tr>\n",
       "<tr><td style=\"text-align:left\">GDP</td><td>3.03e-05<sup></sup></td><td>4.39e-04<sup></sup></td><td>8.24e-06<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(6.00e-05)</td><td>(9.06e-04)</td><td>(1.58e-05)</td></tr>\n",
       "<tr><td style=\"text-align:left\">AGE</td><td>0.117<sup></sup></td><td>1.755<sup></sup></td><td>0.031<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.124)</td><td>(1.920)</td><td>(0.032)</td></tr>\n",
       "<tr><td style=\"text-align:left\">COUTAX_FEMALEUNEMP</td><td>4.18e-04<sup></sup></td><td>5.56e-03<sup></sup></td><td>1.22e-04<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(3.61e-04)</td><td>(5.48e-03)</td><td>(9.52e-05)</td></tr>\n",
       "\n",
       "<td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>32</td><td>32</td><td>32</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.842</td><td>0.841</td><td>0.844</td></tr><tr><td style=\"text-align: left\">AIC</td><td>211.628</td><td>211.665</td><td>211.595</td></tr><tr><td style=\"text-align: left\">BIC</td><td>223.354</td><td>223.390</td><td>223.321</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>15.371<sup>***</sup> (df=31; 25)</td><td>15.219<sup>***</sup> (df=31; 25)</td><td>15.502<sup>***</sup> (df=31; 25)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"3\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x29e3dac90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root_link = lambda mu: mu**.5\n",
    "custom_poisson = PoissonGLM(link=root_link).fit(X,y)\n",
    "\n",
    "poisson_table = sj.RegressionTable([custom_poisson,poisson_id, poisson_log])\n",
    "poisson_table.custom_columns([\"Root Poisson\", \"Identity Poisson\", \"Log Poisson\"])\n",
    "poisson_table.title(\"Poisson GLMs\")\n",
    "display(poisson_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link and distribution must follow certain conditions. The link function must be invertible by Oryx. If it is not invertible, the user can specific a custom inverse: see the Oryx documentation for more information.  \n",
    "\n",
    "The first parameter passed into the distribution for point $i$ is $mu = \\mathbf x^\\top \\beta$. Some distributions need to be re-parametrized into this form, such as the default Oryx Gamma distribution, which is why a custom gamma is used below. The passed distribution should not be instantiated: `Normal`, not `Normal(0,1)`. \n",
    "\n",
    "If a distribution has secondary parameters, the present implementation only supports them shared between all points i.e. shared variance (homoskedasticity) in the normal linear model. When initializing a custom GLM, a tuple of the form `(1., ...)` must be passed. The value used doesn't matter: the model uses only the shape of this argument. If there is only one such parameter, it can be directly passed, and the model will put it into a tuple.  See the above Poisson for examples without auxiliary parameters, and the below models for examples with one.\n",
    "\n",
    "The default beta initialization is an IRLS guess using $\\mathbf y$ as $\\mathbf mu$ except for the Bernoulli GLM which initializes all parameters to $0$. A custom initialization can be passed so long as it takes `(X,y,link, inverse_link, error_distribution, aux_params)` as arguments, where `aux_params` is the shared variable discussed above. \n",
    "\n",
    "If a custom GLM is nan-ing out, the error messages (even with `jax_debug_nans=True`) will be pretty uninformative, but the issue is likely a consequence of support/domain mismatches between the distribution and link function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Custom Gamma and Inverse Gaussian GLMs<br><table style=\"text-align:center\"><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(YES)</td><td>(YES)</td><td>(YES)</td><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">Log Gamma</td><td colspan=\"1\">Inverse Squared Gamma</td><td colspan=\"1\">Log Inverse Gaussian</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>5.658<sup>***</sup></td><td>5.54e-04<sup>***</sup></td><td>5.532<sup>*</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.596)</td><td>(1.72e-04)</td><td>(2.777)</td></tr>\n",
       "<tr><td style=\"text-align:left\">COUTAX</td><td>-2.38e-03<sup>***</sup></td><td>-9.58e-07<sup>***</sup></td><td>-2.27e-03<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(8.44e-04)</td><td>(2.40e-07)</td><td>(3.93e-03)</td></tr>\n",
       "<tr><td style=\"text-align:left\">UNEMPF</td><td>-0.100<sup>***</sup></td><td>-3.89e-05<sup>***</sup></td><td>-0.096<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.027)</td><td>(8.11e-06)</td><td>(0.124)</td></tr>\n",
       "<tr><td style=\"text-align:left\">MOR</td><td>4.81e-03<sup>***</sup></td><td>1.05e-06<sup>**</sup></td><td>5.08e-03<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(1.43e-03)</td><td>(3.89e-07)</td><td>(6.66e-03)</td></tr>\n",
       "<tr><td style=\"text-align:left\">ACT</td><td>-6.66e-03<sup>***</sup></td><td>-1.84e-06<sup>***</sup></td><td>-6.46e-03<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(2.30e-03)</td><td>(5.44e-07)</td><td>(0.011)</td></tr>\n",
       "<tr><td style=\"text-align:left\">GDP</td><td>8.17e-06<sup></sup></td><td>2.44e-09<sup></sup></td><td>8.06e-06<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(6.30e-06)</td><td>(1.83e-09)</td><td>(2.88e-05)</td></tr>\n",
       "<tr><td style=\"text-align:left\">AGE</td><td>0.030<sup>**</sup></td><td>8.75e-06<sup>**</sup></td><td>0.029<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.013)</td><td>(3.35e-06)</td><td>(0.061)</td></tr>\n",
       "<tr><td style=\"text-align:left\">COUTAX_FEMALEUNEMP</td><td>1.18e-04<sup>***</sup></td><td>4.66e-08<sup>***</sup></td><td>1.13e-04<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(3.79e-05)</td><td>(1.13e-08)</td><td>(1.74e-04)</td></tr>\n",
       "\n",
       "<td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>32</td><td>32</td><td>32</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.842</td><td>0.843</td><td>0.840</td></tr><tr><td style=\"text-align: left\">AIC</td><td>181.166</td><td>181.035</td><td>250.058</td></tr><tr><td style=\"text-align: left\">BIC</td><td>192.892</td><td>192.761</td><td>261.784</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>15.355<sup>***</sup> (df=31; 25)</td><td>15.437<sup>***</sup> (df=31; 25)</td><td>15.112<sup>***</sup> (df=31; 25)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"3\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x29f85eb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statjax.glm import GLM\n",
    "from oryx.distributions import InverseGaussian, Gamma\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# reparametrize the gamma distribution to NEF form\n",
    "def GammaNEF(mu, phi):\n",
    "    concentration = 1 / phi \n",
    "    rate = 1 / (mu * phi)\n",
    "    return Gamma(concentration, rate)\n",
    "    \n",
    "\n",
    "custom_log_link= lambda mu: jnp.log(mu)\n",
    "\n",
    "custom_gamma_1 = GLM(custom_log_link, GammaNEF, 1. ).fit(X,y)\n",
    "custom_gamma_2 =  GLM(sj.glm.inverse_squared_link, sj.probability.GammaNEF, 1. ).fit(X,y)\n",
    "\n",
    "custom_invnormal = GLM(custom_log_link, InverseGaussian, 1. ).fit(X,y)\n",
    "\n",
    "\n",
    "custom_glm_table = sj.RegressionTable([custom_gamma_1,\n",
    "                                        custom_gamma_2,\n",
    "                                        custom_invnormal,\n",
    "                                        ])\n",
    "\n",
    "custom_glm_table.custom_columns([\"Log Gamma\", \"Inverse Squared Gamma\", \"Log Inverse Gaussian\"])\n",
    "custom_glm_table.title_text = \"Custom Gamma and Inverse Gaussian GLMs\"\n",
    "display(custom_glm_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BernoulliGLM class uses a logit link by default. To use a probit link instead, simply use the method from `statjax.glm`. This example uses the breast cancer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuacy of logit and probit glms: (0.9384885764499121, 0.9314586994727593)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Logit and Probit GLMs<br><table style=\"text-align:center\"><tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(target)</td><td>(target)</td><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">Logit</td><td colspan=\"1\">Probit</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td></tr>\n",
       "<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>12.108<sup></sup></td><td>6.571<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(10.395)</td><td>(6.125)</td></tr>\n",
       "<tr><td style=\"text-align:left\">mean_radius</td><td>6.018<sup>**</sup></td><td>3.563<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(2.332)</td><td>(1.347)</td></tr>\n",
       "<tr><td style=\"text-align:left\">mean_texture</td><td>-0.362<sup>***</sup></td><td>-0.205<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.089)</td><td>(0.049)</td></tr>\n",
       "<tr><td style=\"text-align:left\">mean_perimeter</td><td>-0.569<sup>***</sup></td><td>-0.339<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.215)</td><td>(0.126)</td></tr>\n",
       "<tr><td style=\"text-align:left\">mean_area</td><td>-0.040<sup>**</sup></td><td>-0.024<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.018)</td><td>(0.010)</td></tr>\n",
       "<tr><td style=\"text-align:left\">mean_smoothness</td><td>-121.484<sup>***</sup></td><td>-67.950<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(30.868)</td><td>(17.036)</td></tr>\n",
       "\n",
       "<td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>569</td><td>569</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.805</td><td>0.805</td></tr><tr><td style=\"text-align: left\">AIC</td><td>576.048</td><td>575.521</td></tr><tr><td style=\"text-align: left\">BIC</td><td>602.112</td><td>601.584</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>386.074<sup>***</sup> (df=568; 564)</td><td>386.478<sup>***</sup> (df=568; 564)</td></tr>\n",
       "<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"2\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x169eeef30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statjax.glm import BernoulliGLM\n",
    "\n",
    "import sklearn.datasets\n",
    "X2, y2 = sklearn.datasets.load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "X2= X2[X2.columns[list(range(5))]]\n",
    "\n",
    "logit_glm = BernoulliGLM().fit(X2,y2)\n",
    "probit_glm = BernoulliGLM(link = sj.glm.probit_link).fit(X2,y2)\n",
    "print(f\"accuacy of logit and probit glms: {((((logit_glm.predict(X2)) > .5) == y2).mean(), ((probit_glm.predict((X2)) > .5) == y2).mean())}\")\n",
    "\n",
    "propensity_table = sj.RegressionTable([logit_glm, probit_glm])\n",
    "propensity_table.custom_columns([\"Logit\", \"Probit\"])\n",
    "propensity_table.title(\"Logit and Probit GLMs\")\n",
    "display(propensity_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized GLMs\n",
    "\n",
    "All models are less stable than the previous models.\n",
    "<!-- \n",
    "The package also provides access to basic regularized models, as well as functionality for the user to define linear models according to a predict, loss, and regularization function. The user can define arbitrary NLMs by loss, predict, and regularization in a similar way to the GLMs above, but the models tend to be unstable.  \n",
    "\n",
    "# import sklearn.datasets\n",
    "# from src.statjax.nlm import ElasticNet, LASSO\n",
    "# from src.statjax import Ridge\n",
    "\n",
    "# X,y = sklearn.datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
    "# r = sj.RegressionTable([ sj.OLS().fit(X,y), NormalGLM().fit(X,y), ElasticNet(100,100).fit(X,y), Ridge(100).fit(X,y), ElasticNet(0,100).fit(X,y), LASSO(100).fit(X,y)])\n",
    "# r.custom_columns([\"OLS\", \"Normal GLM\", \"ElasticNet\", \"Ridge (Analytic)\", \"Ridge (Gradient)\", \"LASSO\"])\n",
    "# display(r)\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian General Linear Models\n",
    "\n",
    "The `BayesGLM` model extends the functionality of the previous section by allowing the user to specify a prior for $\\beta$. Unlike the error distribution, this prior must be fully instantiated. The prior must produce samples in $\\R^k$ where $k$ is the same dimensionality as $\\mathbf x_i$. Fortunately, it's easy to combine distributions into a single object: see the example below. Here, we know that the dataset has seven dimensions, and we know the model will add an intercept as the first column, so we have an 8-dimensional prior. \n",
    "\n",
    "The model is fit using MCMC, and the point estimates are the posterior medians.\n",
    "\n",
    "Unlike the GLMS, no canonical models are provided. Pass the instanciated prior distribution between the error distribution and auxiliary error params. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(YES)</td><td>(YES)</td><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">Normal(0,1)-Gamma</td><td colspan=\"1\">Laplace(0,1)-Gamma</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td></tr>\n",
       "<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>0.064</td><td>0.076</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">COUTAX</td><td>0.053</td><td>0.052</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">UNEMPF</td><td>0.211</td><td>0.091</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">MOR</td><td>0.348</td><td>0.332</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">ACT</td><td>-0.197</td><td>-0.182</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">GDP</td><td>2.75e-04</td><td>2.66e-04</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">AGE</td><td>0.934</td><td>1.011</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">COUTAX_FEMALEUNEMP</td><td>-1.32e-03</td><td>-1.24e-03</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td></tr>\n",
       "\n",
       "<td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>32</td><td>32</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.748</td><td>0.734</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>8.527<sup>***</sup> (df=31; 25)</td><td>7.945<sup>***</sup> (df=31; 25)</td></tr>\n",
       "<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"2\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x29e378b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from oryx import distributions\n",
    "import jax.numpy as jnp\n",
    "\n",
    "laplace_prior =distributions.Independent(distributions.Laplace(jnp.zeros(8),jnp.ones(8)),1)\n",
    "normal_prior = distributions.MultivariateNormalDiag(jnp.zeros((8)), jnp.ones(8) )\n",
    "\n",
    "bm_normal = sj.BayesGLM(sj.glm.identity_link, sj.probability.GammaNEF, normal_prior, (1.,),).fit(X,y)\n",
    "bm_laplace = sj.BayesGLM(sj.glm.identity_link, sj.probability.GammaNEF, laplace_prior, (1.,)).fit(X,y)\n",
    "\n",
    "bayes_table = sj.RegressionTable([bm_normal, bm_laplace])\n",
    "bayes_table.custom_columns([\"Normal(0,1)-Gamma\", \"Laplace(0,1)-Gamma\"])\n",
    "display(bayes_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can analyze the MCMC by looking at the training samples. Here, we see that the posterior of the variance of the error model is skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_samples = bm_normal.mcmc_samples[\"beta\"]\n",
    "aux_samples = bm_normal.mcmc_samples[\"aux_params\"][0]\n",
    "\n",
    "import seaborn as sns\n",
    "sns.histplot(aux_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the modular design, we can impose arbitrary priors. Here's regularization towards 1 and 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"5\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(YES)</td><td>(YES)</td><td>(YES)</td><td>(YES)</td><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">Normal(1,1)-Poisson</td><td colspan=\"1\">Laplace(1,1)-Poisson</td><td colspan=\"1\">Normal(10,1)-Poisson</td><td colspan=\"1\">Laplace(10,1)-Poisson</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td></tr>\n",
       "<tr><td colspan=\"5\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>1.011</td><td>0.997</td><td>9.800</td><td>9.942</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">COUTAX</td><td>0.068</td><td>0.066</td><td>0.228</td><td>0.095</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">UNEMPF</td><td>0.695</td><td>0.775</td><td>5.476</td><td>1.469</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">MOR</td><td>0.286</td><td>0.309</td><td>-0.377</td><td>0.093</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">ACT</td><td>-0.235</td><td>-0.256</td><td>-1.261</td><td>-0.623</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">GDP</td><td>1.61e-04</td><td>2.23e-04</td><td>-2.91e-04</td><td>3.62e-04</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">AGE</td><td>1.037</td><td>1.014</td><td>5.654</td><td>3.067</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">COUTAX_FEMALEUNEMP</td><td>-2.18e-03</td><td>-2.14e-03</td><td>-0.010</td><td>-3.58e-03</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td></td></tr>\n",
       "\n",
       "<td colspan=\"5\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>32</td><td>32</td><td>32</td><td>32</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.760</td><td>0.709</td><td>-0.063</td><td>0.677</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>9.099<sup>***</sup> (df=31; 25)</td><td>6.994<sup>***</sup> (df=31; 25)</td><td>-0.171<sup>***</sup> (df=31; 25)</td><td>6.039<sup>***</sup> (df=31; 25)</td></tr>\n",
       "<tr><td colspan=\"5\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"4\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x2b41b1160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "laplace_prior1 =distributions.Independent(distributions.Laplace(jnp.ones(8),(jnp.ones(8) )),1)\n",
    "normal_prior1 = distributions.MultivariateNormalDiag(jnp.ones((8)), jnp.ones(8) )\n",
    "\n",
    "\n",
    "laplace_prior10 =distributions.Independent(distributions.Laplace(jnp.ones(8)*10,(jnp.ones(8) )),1)\n",
    "normal_prior10 = distributions.MultivariateNormalDiag(jnp.ones((8))*10, jnp.ones(8) )\n",
    "\n",
    "\n",
    "bm_normal = sj.BayesGLM(sj.glm.identity_link, distributions.Poisson, normal_prior1, ).fit(X,y)\n",
    "bm_laplace = sj.BayesGLM(sj.glm.identity_link, distributions.Poisson, laplace_prior1, ).fit(X,y)\n",
    "\n",
    "bm_normal_10 = sj.BayesGLM(sj.glm.identity_link, distributions.Poisson, normal_prior10, ).fit(X,y)\n",
    "bm_laplace_10 = sj.BayesGLM(sj.glm.identity_link, distributions.Poisson, laplace_prior10, ).fit(X,y)\n",
    "\n",
    "bayes_table2 = sj.RegressionTable([bm_normal, bm_laplace, bm_normal_10, bm_laplace_10])\n",
    "bayes_table2.custom_columns([\"Normal(1,1)-Poisson\", \"Laplace(1,1)-Poisson\",\"Normal(10,1)-Poisson\", \"Laplace(10,1)-Poisson\"])\n",
    "display(bayes_table2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, 95% credible intervals for $\\beta$ drawn from the MCMC posterior are pre-computed for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-9.29888595e-01, -5.75009712e-03, -9.33199511e-01,\n",
       "        -5.78936255e-02, -7.09097804e-01, -1.58410368e-03,\n",
       "        -5.68336735e-01, -5.44568029e-03],\n",
       "       [ 3.00618932e+00,  1.42615280e-01,  2.48536094e+00,\n",
       "         6.31231850e-01,  2.21597362e-01,  1.90954729e-03,\n",
       "         2.67226057e+00,  1.04320450e-03]], dtype=float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_normal.ci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic-Net GLMs\n",
    "\n",
    "Elastic net regularization following Glmnet is available for all GLMs, including custom models. The objective for each step, closely following [Tay et al. 2023](https://arxiv.org/pdf/2103.03475), is \n",
    "\n",
    "$$\n",
    "\\argmin_{\\beta} \\left[ (\\mathbf z^{(t)} - \\mathbf X \\beta )^\\top \\mathbf W^{(t)}  (\\mathbf z^{(t)} - \\mathbf X \\beta )^\\top + n\\left((1-\\alpha)\\beta^\\top \\beta + 2 \\alpha ||\\beta||_1^1\\right)\\right]\n",
    "$$\n",
    "\n",
    "The model is still fit via IRLS. \n",
    "Statjax departs from the paper by regularizing the intercept and not varying $\\lambda$. This is to maintain consistency with Glmnet. By default, $\\alpha = .5$. Here, we use large values of $\\lambda$ to compensate for the small magnitude of $\\beta$ given an inverse link. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Regularized Gamma GLMs<br><table style=\"text-align:center\"><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(YES)</td><td>(YES)</td><td>(YES)</td><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">Elastic</td><td colspan=\"1\">Ridge</td><td colspan=\"1\">Lasso</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>2.64e-03</td><td>4.95e-03</td><td>1.28e-03</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">COUTAX</td><td>-3.14e-05</td><td>-3.40e-05</td><td>-2.98e-05</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">UNEMPF</td><td>-1.43e-03</td><td>-1.52e-03</td><td>-1.37e-03</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">MOR</td><td>7.16e-05</td><td>7.14e-05</td><td>7.17e-05</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">ACT</td><td>-9.51e-05</td><td>-9.82e-05</td><td>-9.33e-05</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">GDP</td><td>1.40e-07</td><td>1.41e-07</td><td>1.40e-07</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">AGE</td><td>5.19e-04</td><td>5.20e-04</td><td>5.20e-04</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">COUTAX_FEMALEUNEMP</td><td>1.62e-06</td><td>1.74e-06</td><td>1.55e-06</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td></tr>\n",
       "\n",
       "<td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>32</td><td>32</td><td>32</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.828</td><td>0.832</td><td>0.825</td></tr><tr><td style=\"text-align: left\">AIC</td><td>183.236</td><td>182.587</td><td>183.666</td></tr><tr><td style=\"text-align: left\">BIC</td><td>194.962</td><td>194.313</td><td>195.392</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>13.817<sup>***</sup> (df=31; 25)</td><td>14.219<sup>***</sup> (df=31; 25)</td><td>13.566<sup>***</sup> (df=31; 25)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"3\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x2adf62bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lam = .01 \n",
    "enet_gamma = GammaGLM( lam=1000.).fit(X, y)\n",
    "lasso_gamma = GammaGLM( lam=1000., alpha=1.).fit(X, y)\n",
    "ridge_gamma = GammaGLM( lam=1000., alpha=0.).fit(X, y)\n",
    "regularized_table = sj.RegressionTable([enet_gamma, ridge_gamma, lasso_gamma, ])\n",
    "regularized_table.custom_columns([\"Elastic\", \"Ridge\", \"Lasso\"])\n",
    "regularized_table.title(\"Regularized Gamma GLMs\")\n",
    "display(regularized_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Models\n",
    "\n",
    "Statjax currently offers four causal ate estimators. We'll first download the Lalonde dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:24: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:24: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/kq/xxx341651fg6vk0b96q6j7r00000gn/T/ipykernel_81470/1230381039.py:24: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  files = [pd.read_csv(file_name, sep='\\s+', header=None, names=columns) for file_name in file_names]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# https://users.nber.org/~rdehejia/nswdata2.html\n",
    "\n",
    "columns = [\"training\",   # Treatment assignment indicator\n",
    "           \"age\",        # Age of participant\n",
    "           \"education\",  # Years of education\n",
    "           \"black\",      # Indicate whether individual is black\n",
    "           \"hispanic\",   # Indicate whether individual is hispanic\n",
    "           \"married\",    # Indicate whether individual is married\n",
    "           \"no_degree\",  # Indicate if individual has no high-school diploma\n",
    "           \"re74\",       # Real earnings in 1974, prior to study participation\n",
    "           \"re75\",       # Real earnings in 1975, prior to study participation\n",
    "           \"re78\"]       # Real earnings in 1978, after study end\n",
    "\n",
    "\n",
    "file_names = [\"http://www.nber.org/~rdehejia/data/nswre74_treated.txt\",\n",
    "              \"http://www.nber.org/~rdehejia/data/nswre74_control.txt\",\n",
    "              \"http://www.nber.org/~rdehejia/data/psid_controls.txt\",\n",
    "              \"http://www.nber.org/~rdehejia/data/psid2_controls.txt\",\n",
    "              \"http://www.nber.org/~rdehejia/data/psid3_controls.txt\",\n",
    "              \"http://www.nber.org/~rdehejia/data/cps_controls.txt\",\n",
    "              \"http://www.nber.org/~rdehejia/data/cps2_controls.txt\",\n",
    "              \"http://www.nber.org/~rdehejia/data/cps3_controls.txt\"]\n",
    "files = [pd.read_csv(file_name, sep='\\s+', header=None, names=columns) for file_name in file_names]\n",
    "lalonde = pd.concat(files, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`statjax` follows the Rudin causal model, with $D$ indicating treatment status, $X$ indicating covariates, and $Y$ indicating outcomes. We remove points with features outside the range of that feature among the treated points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n violating overlap: 7407\n"
     ]
    }
   ],
   "source": [
    "from statjax import causal\n",
    "\n",
    "D = lalonde[[\"training\"]]\n",
    "X = lalonde[[\"age\", \"education\", \"black\", \"hispanic\", \"married\", \"no_degree\", \"re74\", \"re75\"]]\n",
    "Y = lalonde[[\"re78\"]]\n",
    "\n",
    "in_overlap = causal.check_overlap(D,lalonde[list(X.columns)])\n",
    "\n",
    "print(f\"n violating overlap: {sum(~in_overlap)}\")\n",
    "D = D[in_overlap]\n",
    "X = X[in_overlap]\n",
    "Y = Y[in_overlap]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ExperimentalEstimator class assumes random assignment, and simply compares the group means. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ols coef on treatment w/o controls: -6497.048111659362\n",
      "ols coef on treatment w/ controls: -107.5805714583357\n",
      "naive ate: -6497.048111659312\n"
     ]
    }
   ],
   "source": [
    "linreg = sj.OLS().fit(D,Y)\n",
    "\n",
    "linreg_controlled = sj.OLS().fit(jnp.hstack([X.values, D.values]),Y)\n",
    "print(f\"ols coef on treatment w/o controls: {linreg.beta[1]}\")\n",
    "print(f\"ols coef on treatment w/ controls: {linreg_controlled.beta[1]}\")\n",
    "\n",
    "naive_model = causal.ExperimentalEstimator().fit(D,Y)\n",
    "exp_est = naive_model.ate\n",
    "print(f\"naive ate: {exp_est}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RegressionEstimator fits two regression models, one for each treatment outcome, and compares the difference in expectation. It defaults to linear estimators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ols imputation ate: -2809.6824574998304\n"
     ]
    }
   ],
   "source": [
    "regression_model = causal.RegressionEstimator().fit(D,X, Y)\n",
    "print(f\"ols imputation ate: {regression_model.ate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It allows for more other regression models. While it takes longer to train, here we use the NNRegression model, which is a flexible neural net that can be used as a miscellaneous non-parametric model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural imputation ate: -6818.2196256187635\n"
     ]
    }
   ],
   "source": [
    "from statjax.nn import NNRegression\n",
    "\n",
    "nn_regression_model =  causal.RegressionEstimator(model=NNRegression(hidden_layers = (128,64)))\n",
    "nn_regression_model.fit(D,X,Y)\n",
    "print(f\"neural imputation ate: {nn_regression_model.ate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PropensityScoreEstimator fits $p(D_i=1|X_i)$  then uses that as inverse weights. The default model is a logistic regression, but the user can specify alternatives.\n",
    "\n",
    "Note that the model automatically prunes points with $p>1-\\delta$ or $p<\\delta$, with the default at initialization as $\\delta = .1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit ate: 2186.5376403319, probit ate: 2571.334587733147, nn ate: 1320.169593785673\n"
     ]
    }
   ],
   "source": [
    "from jax.nn import sigmoid\n",
    "\n",
    "logit_model = causal.PropensityScoreEstimator().fit(D,X,Y)\n",
    "probit_model = causal.PropensityScoreEstimator(propensity_model=BernoulliGLM(link=sj.glm.probit_link)).fit(D,X,Y)\n",
    "\n",
    "nn_ps_model = causal.PropensityScoreEstimator(propensity_model=NNRegression(hidden_layers = (32,32),output_activation=sigmoid)).fit(D,X,Y)\n",
    "\n",
    "print(f\"logit ate: {logit_model.ate}, probit ate: {probit_model.ate}, nn ate: {nn_ps_model.ate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The propensities can be analyzed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1.13891559e-70, 4.75170118e-30, 1.74601157e-14, 2.26063828e-05,\n",
       "       3.66121309e-01], dtype=float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.percentile(nn_ps_model.propensities, jnp.array([0,25,50,75,100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, `statjax` contains a doubly robust estimator, which can take a custom propensity_model and outcome_model. To demonstrate why pruning is important, we can fit a DRE without any pruning ($\\delta = 0$) to see the effect on the ATE.  \n",
    "\n",
    "As above, the bulk of the runtime is the outcome network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dre ate: 2084.2915877457867\n",
      "neural propensity dre ate: 1137.4334587308522\n",
      "fully neural dre ate: 2421.439895598937\n",
      "unpruned dre ate: 12719550904.208557\n"
     ]
    }
   ],
   "source": [
    "dre_model = causal.DREstimator().fit(D,X,Y)\n",
    "dre_model_unpruned = causal.DREstimator(delta = 0.).fit(D,X,Y)\n",
    "\n",
    "neural_dre = causal.DREstimator(propensity_model=NNRegression(hidden_layers = (32,32),output_activation=sigmoid)).fit(D,X,Y)\n",
    "fully_neural_dre = causal.DREstimator(outcome_model=NNRegression(hidden_layers=(128, 128, 64, 64)),\n",
    "                              propensity_model=NNRegression(hidden_layers = (32,32),output_activation=sigmoid),\n",
    "                              ).fit(D,X,Y)\n",
    "\n",
    "print(f\"dre ate: {dre_model.ate}\\nneural propensity dre ate: {neural_dre.ate}\\nfully neural dre ate: {fully_neural_dre.ate}\\nunpruned dre ate: {dre_model_unpruned.ate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submodels of any causal model can be accessed at model0/model1 for regression-based models and propensity_model for propensity scoring models. Here are all 3 from the DRE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(training)</td><td>(re78)</td><td>(re78)</td><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">P(D=1|X)</td><td colspan=\"1\">E[Y|X,D=0]</td><td colspan=\"1\">E[Y|X,D=1]</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>-4.183<sup>**</sup></td><td>4361.918<sup>***</sup></td><td>-1508.424<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(1.669)</td><td>(599.002)</td><td>(6006.589)</td></tr>\n",
       "<tr><td style=\"text-align:left\">age</td><td>0.023<sup></sup></td><td>-110.543<sup>***</sup></td><td>83.562<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.016)</td><td>(8.069)</td><td>(85.387)</td></tr>\n",
       "<tr><td style=\"text-align:left\">education</td><td>-0.069<sup></sup></td><td>280.199<sup>***</sup></td><td>623.961<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.083)</td><td>(40.582)</td><td>(395.287)</td></tr>\n",
       "<tr><td style=\"text-align:left\">black</td><td>3.007<sup>**</sup></td><td>-950.709<sup>***</sup></td><td>-1140.014<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(1.181)</td><td>(179.060)</td><td>(1981.176)</td></tr>\n",
       "<tr><td style=\"text-align:left\">hispanic</td><td>1.270<sup></sup></td><td>-182.150<sup></sup></td><td>304.327<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(1.479)</td><td>(232.658)</td><td>(3057.645)</td></tr>\n",
       "<tr><td style=\"text-align:left\">married</td><td>-0.914<sup>**</sup></td><td>211.242<sup></sup></td><td>1032.440<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.432)</td><td>(148.457)</td><td>(1589.880)</td></tr>\n",
       "<tr><td style=\"text-align:left\">no_degree</td><td>0.142<sup></sup></td><td>370.443<sup>*</sup></td><td>-319.009<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.403)</td><td>(197.691)</td><td>(1807.132)</td></tr>\n",
       "<tr><td style=\"text-align:left\">re74</td><td>-5.67e-04<sup>**</sup></td><td>0.318<sup>***</sup></td><td>0.039<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(2.61e-04)</td><td>(0.012)</td><td>(0.160)</td></tr>\n",
       "<tr><td style=\"text-align:left\">re75</td><td>-3.12e-05<sup></sup></td><td>0.469<sup>***</sup></td><td>0.089<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(8.72e-05)</td><td>(0.013)</td><td>(0.244)</td></tr>\n",
       "\n",
       "<td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>14699</td><td>14514</td><td>185</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.130</td><td>0.414</td><td>0.050</td></tr><tr><td style=\"text-align: left\">AIC</td><td>20512.576</td><td></td><td></td></tr><tr><td style=\"text-align: left\">BIC</td><td>20580.936</td><td></td><td></td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>243.112<sup>***</sup> (df=14698; 14691)</td><td>1136.882<sup>***</sup> (df=14513; 14506)</td><td>1.023<sup></sup> (df=184; 177)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"3\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x2dc2ed7f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dre_table = sj.RegressionTable([dre_model.propensity_model, dre_model.model0, dre_model.model1])\n",
    "dre_table.custom_columns([\"P(D=1|X)\", \"E[Y|X,D=0]\", \"E[Y|X,D=1]\"])\n",
    "dre_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Personal (3.12)",
   "language": "python",
   "name": "personal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
