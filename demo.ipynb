{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This library is a set of personal implementations. It has a few goals: it compiles the data science tools that I use day-to-day in a single place, it's a place for me to practice coding to keep from getting too rusty, and it's a way for me to check my understanding of new models by implementing them.\n",
    "\n",
    "The main convenience feature over `sklearn` or `statsmodels` is a port of the Python `stargazer` package that can produce latex tables displaying any of the linear models in the package side-by-side. It duplicates part of the `statsmodels` GLM functionality, and provides a general GLM class that the user can initialize with an arbitrary link function and `oryx` distribution.  The backend of the package is written in `jax`. Overhead is higher, but the package will outperform `statsmodels` and `sklearn` in large-sample or high-dimensional cases. See the demo notebook for specifics. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks through the core functionality of the package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics and OLS\n",
    "\n",
    "To begin, let's load the Longly dataset from `statsmodels`. `statjax` follows the `sklearn` convention of `model().fit(X,y)` rather than the `statsmodels` convention of model(y,X).fit(). Models can take dataframe, array, or ModelMatrix (see below) inputs. They will add intercepts unless add_intercept = False is passed in fit. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statjax as sj\n",
    "from statjax import OLS\n",
    "\n",
    "\n",
    "longley = sm.datasets.longley.load_pandas()\n",
    "X = longley.exog\n",
    "y = longley.endog\n",
    "\n",
    "ols= OLS().fit(X, y)\n",
    "ols_no_intercept= sj.OLS().fit(X, y, add_intercept=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OLS model supports non-robust, heteroskedasticity-robust, and clustered standard errors following [Cameron and Miller (2015)](https://cameron.econ.ucdavis.edu/research/Cameron_Miller_JHR_2015_February.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_robust = OLS(\"robust\").fit(X,y,)\n",
    "decade = X[\"YEAR\"] // 10\n",
    "ols_clustered = OLS(\"clustered\").fit(X, y, decade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize, use the table functionality, which closely follows the python `stargazer` package â€“ see their documentation for table options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "OLS regressions<br><table style=\"text-align:center\"><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(TOTEMP)</td><td>(TOTEMP)</td><td>(TOTEMP)</td><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">OLS</td><td colspan=\"1\">OLS (robust)</td><td colspan=\"1\">OLS (clustered)</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>-3482258.637<sup>***</sup></td><td>-3482258.637<sup>***</sup></td><td>-3482258.637<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(4.69e-03)</td><td>(6.08e-03)</td><td>(1.38e-03)</td></tr>\n",
       "<tr><td style=\"text-align:left\">GNPDEFL</td><td>15.062<sup></sup></td><td>15.062<sup></sup></td><td>15.062<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(83.113)</td><td>(87.551)</td><td>(45.657)</td></tr>\n",
       "<tr><td style=\"text-align:left\">GNP</td><td>-0.036<sup>*</sup></td><td>-0.036<sup></sup></td><td>-0.036<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.019)</td><td>(0.022)</td><td>(6.48e-03)</td></tr>\n",
       "<tr><td style=\"text-align:left\">UNEMP</td><td>-2.020<sup>***</sup></td><td>-2.020<sup>***</sup></td><td>-2.020<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.268)</td><td>(0.300)</td><td>(0.073)</td></tr>\n",
       "<tr><td style=\"text-align:left\">ARMED</td><td>-1.033<sup>***</sup></td><td>-1.033<sup>***</sup></td><td>-1.033<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.179)</td><td>(0.110)</td><td>(0.063)</td></tr>\n",
       "<tr><td style=\"text-align:left\">POP</td><td>-0.051<sup></sup></td><td>-0.051<sup></sup></td><td>-0.051<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.206)</td><td>(0.261)</td><td>(0.057)</td></tr>\n",
       "<tr><td style=\"text-align:left\">YEAR</td><td>1829.151<sup>***</sup></td><td>1829.151<sup>***</sup></td><td>1829.151<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(11.349)</td><td>(13.869)</td><td>(3.011)</td></tr>\n",
       "\n",
       "<td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>16</td><td>16</td><td>16</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.995</td><td>0.995</td><td>0.995</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>251.646<sup>***</sup> (df=15; 10)</td><td>251.646<sup>***</sup> (df=15; 10)</td><td>251.646<sup>***</sup> (df=15; 10)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"3\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x16cee5ee0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ols_table = sj.RegressionTable([ols , ols_robust, ols_clustered])\n",
    "ols_table.custom_columns([\"OLS\", \"OLS (robust)\", \"OLS (clustered)\"])\n",
    "ols_table.title(\"OLS regressions\")\n",
    "display(ols_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tables can be converted to latex for display - see demo_table.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{@{\\extracolsep{5pt}}lccc}\n",
      "\\\\[-1.8ex]\\hline\n",
      "\\hline \\\\[-1.8ex]\n",
      "\\textit{Dependent variable: } &  \\multicolumn{3}{c}{TOTEMP} \n",
      "% \\\\[-1.8ex]\n",
      "\\cr \\cline{2-4}\n",
      "\\\\[-1.8ex]\\\\[-1.8ex] & \\multicolumn{1}{c}{OLS} & \\multicolumn{1}{c}{OLS (robust)} & \\multicolumn{1}{c}{OLS (clustered)}  \\\\\n",
      "\\\\[-1.8ex] & (1) & (2) & (3) \\\\\n",
      "\\hline \\\\[-1.8ex]\n",
      " Intercept & -3482258.637$^{***}$ & -3482258.637$^{***}$ & -3482258.637$^{***}$ \\\\\n",
      "& (4.69e-03) & (6.08e-03) & (1.38e-03) \\\\\n",
      " GNPDEFL & 15.062$^{}$ & 15.062$^{}$ & 15.062$^{}$ \\\\\n",
      "& (83.113) & (87.551) & (45.657) \\\\\n",
      " GNP & -0.036$^{*}$ & -0.036$^{}$ & -0.036$^{***}$ \\\\\n",
      "& (0.019) & (0.022) & (6.48e-03) \\\\\n",
      " UNEMP & -2.020$^{***}$ & -2.020$^{***}$ & -2.020$^{***}$ \\\\\n",
      "& (0.268) & (0.300) & (0.073) \\\\\n",
      " ARMED & -1.033$^{***}$ & -1.033$^{***}$ & -1.033$^{***}$ \\\\\n",
      "& (0.179) & (0.110) & (0.063) \\\\\n",
      " POP & -0.051$^{}$ & -0.051$^{}$ & -0.051$^{}$ \\\\\n",
      "& (0.206) & (0.261) & (0.057) \\\\\n",
      " YEAR & 1829.151$^{***}$ & 1829.151$^{***}$ & 1829.151$^{***}$ \\\\\n",
      "& (11.349) & (13.869) & (3.011) \\\\\n",
      "\\hline \\\\[-1.8ex]\n",
      " Observations & 16 & 16 & 16 \\\\\n",
      " $R^2$ & 0.995 & 0.995 & 0.995 \\\\\n",
      " F Statistic & 251.646$^{***}$ (df=15; 10) & 251.646$^{***}$ (df=15; 10) & 251.646$^{***}$ (df=15; 10) \\\\\n",
      "\\hline\n",
      "\\hline \\\\[-1.8ex]\n",
      "\\textit{Note:} & \\multicolumn{3}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print(ols_table.render_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RegressionTable can take either a single model or a list of models. If arrays are passed, the table will substitute variable names. The table will produce rows for all variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(TOTEMP)</td><td>(y)</td><td>(TOTEMP)</td><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>-3482258.637<sup>***</sup></td><td>-3482258.637<sup>***</sup></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(4.69e-03)</td><td>(4.69e-03)</td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">GNPDEFL</td><td>15.062<sup></sup></td><td></td><td>-52.994<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(83.113)</td><td></td><td>(129.545)</td></tr>\n",
       "<tr><td style=\"text-align:left\">GNP</td><td>-0.036<sup>*</sup></td><td></td><td>0.071<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.019)</td><td></td><td>(0.030)</td></tr>\n",
       "<tr><td style=\"text-align:left\">UNEMP</td><td>-2.020<sup>***</sup></td><td></td><td>-0.423<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.268)</td><td></td><td>(0.418)</td></tr>\n",
       "<tr><td style=\"text-align:left\">ARMED</td><td>-1.033<sup>***</sup></td><td></td><td>-0.573<sup>*</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.179)</td><td></td><td>(0.279)</td></tr>\n",
       "<tr><td style=\"text-align:left\">POP</td><td>-0.051<sup></sup></td><td></td><td>-0.414<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.206)</td><td></td><td>(0.321)</td></tr>\n",
       "<tr><td style=\"text-align:left\">YEAR</td><td>1829.151<sup>***</sup></td><td></td><td>48.418<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(11.349)</td><td></td><td>(17.689)</td></tr>\n",
       "<tr><td style=\"text-align:left\">x0</td><td></td><td>15.062<sup></sup></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(83.113)</td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">x1</td><td></td><td>-0.036<sup>*</sup></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.019)</td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">x2</td><td></td><td>-2.020<sup>***</sup></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.268)</td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">x3</td><td></td><td>-1.033<sup>***</sup></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.179)</td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">x4</td><td></td><td>-0.051<sup></sup></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.206)</td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">x5</td><td></td><td>1829.151<sup>***</sup></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(11.349)</td><td></td></tr>\n",
       "\n",
       "<td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>16</td><td>16</td><td>16</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.995</td><td>0.995</td><td>0.988</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>251.646<sup>***</sup> (df=15; 10)</td><td>251.646<sup>***</sup> (df=15; 10)</td><td>121.412<sup>***</sup> (df=15; 10)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"3\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x282fc6f00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_from_arrays = OLS().fit(X.values, y.values)\n",
    "sj.RegressionTable([ols, ols_from_arrays,ols_no_intercept])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final input type supported is formulaic model_matrix. If a model_matrix is passed, the model will predict untransformed data using that model_matrix, meaning that the model will automatically transform untransformed data if passed. The variable names will automatically export. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions are equal: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(TOTEMP)</td><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td></tr>\n",
       "<tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>49160.443<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.159)</td></tr>\n",
       "<tr><td style=\"text-align:left\">GNPDEFL</td><td>39.530<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(9.652)</td></tr>\n",
       "<tr><td style=\"text-align:left\">GNP</td><td>0.037<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(3.32e-03)</td></tr>\n",
       "<tr><td style=\"text-align:left\">ARMED:UNEMP</td><td>-2.59e-04<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(8.85e-05)</td></tr>\n",
       "\n",
       "<td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>16</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.980</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>135.290<sup>***</sup> (df=15; 13)</td></tr>\n",
       "<tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"1\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x1062f9eb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from formulaic import model_matrix\n",
    "\n",
    "y_f,X_f = model_matrix(\"TOTEMP ~ GNPDEFL + GNP + ARMED:UNEMP\", longley.data )\n",
    "\n",
    "formula_model = sj.OLS().fit(X_f, y_f, add_intercept=False)\n",
    "print(f\"predictions are equal: {bool((formula_model.predict(X_f)==formula_model.predict(longley.data)).prod())}\")\n",
    "display(sj.RegressionTable(formula_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " However, it will not support model matrices with different formulas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: Predictor matrix has different features than those used to fit the model.\n"
     ]
    }
   ],
   "source": [
    "different_formula_X = model_matrix(\"GNPDEFL + GNP + ARMED*UNEMP\", longley.data)\n",
    "\n",
    "try:\n",
    "    different_formula_X = model_matrix(\"GNPDEFL + GNP + ARMED*UNEMP\", longley.data)\n",
    "    formula_model.predict(different_formula_X)\n",
    "except Exception as e:\n",
    "    print(f\"error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models\n",
    "## GLM\n",
    "\n",
    "All of the GLM implementations follow Agresti, Foundations of Linear and Generalized Linear Models (2015). The models use either Fisher scoring or iterative least squares to fit $\\beta$, then Newton-Raphson to fit any other parameters of the distribution. The `oryx` library provides the infrastructure for random variables.\n",
    "\n",
    "Normal, Bernoulli, Poisson, Gamma, and Inverse Normal GLMS are supported by default. Certain link functions can be imported from glm as sj.glm.link, currently identity_link, log_link, inverse_link, logit_link, probit_link, and inverse_squared_link. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Base GLMS<br><table style=\"text-align:center\"><tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(YES)</td><td>(YES)</td><td>(YES)</td><td>(YES)</td><td>(YES)</td><td>(YES)</td><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">Normal</td><td colspan=\"1\">Poisson (Identity)</td><td colspan=\"1\">Poisson (Log)</td><td colspan=\"1\">Gamma</td><td colspan=\"1\">Inverse Gaussian</td><td colspan=\"1\">Inverse Gaussian (Identity)</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td><td>(5)</td><td>(6)</td></tr>\n",
       "<tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>137.414<sup>***</sup></td><td>129.525<sup></sup></td><td>5.779<sup>***</sup></td><td>-0.018<sup>*</sup></td><td>-1.07e-03<sup>***</sup></td><td>113.638<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(35.439)</td><td>(87.264)</td><td>(1.477)</td><td>(0.010)</td><td>(3.40e-04)</td><td>(35.800)</td></tr>\n",
       "<tr><td style=\"text-align:left\">COUTAX</td><td>-0.116<sup>**</sup></td><td>-0.109<sup></sup></td><td>-2.47e-03<sup></sup></td><td>4.96e-05<sup>***</sup></td><td>1.91e-06<sup>***</sup></td><td>-0.093<sup>*</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.050)</td><td>(0.123)</td><td>(2.09e-03)</td><td>(1.42e-05)</td><td>(4.77e-07)</td><td>(0.050)</td></tr>\n",
       "<tr><td style=\"text-align:left\">UNEMPF</td><td>-5.186<sup>***</sup></td><td>-4.903<sup></sup></td><td>-0.105<sup></sup></td><td>2.03e-03<sup>***</sup></td><td>7.71e-05<sup>***</sup></td><td>-4.331<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(1.601)</td><td>(3.881)</td><td>(0.068)</td><td>(4.64e-04)</td><td>(1.59e-05)</td><td>(1.545)</td></tr>\n",
       "<tr><td style=\"text-align:left\">MOR</td><td>0.285<sup>***</sup></td><td>0.300<sup></sup></td><td>4.53e-03<sup></sup></td><td>-7.18e-05<sup>***</sup></td><td>-2.27e-06<sup>***</sup></td><td>0.327<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.085)</td><td>(0.210)</td><td>(3.52e-03)</td><td>(2.37e-05)</td><td>(7.91e-07)</td><td>(0.084)</td></tr>\n",
       "<tr><td style=\"text-align:left\">ACT</td><td>-0.420<sup>***</sup></td><td>-0.407<sup></sup></td><td>-6.86e-03<sup></sup></td><td>1.12e-04<sup>***</sup></td><td>3.64e-06<sup>***</sup></td><td>-0.381<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.137)</td><td>(0.350)</td><td>(5.47e-03)</td><td>(3.54e-05)</td><td>(1.14e-06)</td><td>(0.152)</td></tr>\n",
       "<tr><td style=\"text-align:left\">GDP</td><td>4.50e-04<sup></sup></td><td>4.39e-04<sup></sup></td><td>8.24e-06<sup></sup></td><td>-1.47e-07<sup></sup></td><td>-5.10e-09<sup></sup></td><td>4.15e-04<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(3.75e-04)</td><td>(9.06e-04)</td><td>(1.58e-05)</td><td>(1.08e-07)</td><td>(3.66e-09)</td><td>(3.50e-04)</td></tr>\n",
       "<tr><td style=\"text-align:left\">AGE</td><td>1.840<sup>**</sup></td><td>1.755<sup></sup></td><td>0.031<sup></sup></td><td>-5.19e-04<sup>**</sup></td><td>-1.72e-05<sup>**</sup></td><td>1.606<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.772)</td><td>(1.920)</td><td>(0.032)</td><td>(2.10e-04)</td><td>(6.91e-06)</td><td>(0.783)</td></tr>\n",
       "<tr><td style=\"text-align:left\">COUTAX_FEMALEUNEMP</td><td>5.89e-03<sup>**</sup></td><td>5.56e-03<sup></sup></td><td>1.22e-04<sup></sup></td><td>-2.43e-06<sup>***</sup></td><td>-9.31e-08<sup>***</sup></td><td>4.86e-03<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(2.26e-03)</td><td>(5.48e-03)</td><td>(9.52e-05)</td><td>(6.51e-07)</td><td>(2.22e-08)</td><td>(2.18e-03)</td></tr>\n",
       "\n",
       "<td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>32</td><td>32</td><td>32</td><td>32</td><td>32</td><td>32</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.842</td><td>0.841</td><td>0.844</td><td>0.844</td><td>0.841</td><td>0.838</td></tr><tr><td style=\"text-align: left\">AIC</td><td>179.688</td><td>211.665</td><td>11221.361</td><td>180.947</td><td>11485.436</td><td>182.654</td></tr><tr><td style=\"text-align: left\">BIC</td><td>191.414</td><td>223.390</td><td>11233.087</td><td>192.673</td><td>11497.162</td><td>194.380</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>15.271<sup>***</sup> (df=31; 25)</td><td>15.219<sup>***</sup> (df=31; 25)</td><td>15.502<sup>***</sup> (df=31; 25)</td><td>15.509<sup>***</sup> (df=31; 25)</td><td>15.241<sup>***</sup> (df=31; 25)</td><td>14.841<sup>***</sup> (df=31; 25)</td></tr>\n",
       "<tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"6\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x2bd1d6900>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statjax.glm import PoissonGLM, GammaGLM, InverseNormalGLM, NormalGLM\n",
    "\n",
    "scotland =  sm.datasets.scotland.load()\n",
    "X = scotland.exog\n",
    "y = scotland.endog\n",
    "\n",
    "nglm = NormalGLM().fit(X,y) \n",
    "\n",
    "poisson_id = PoissonGLM(link=sj.glm.identity_link).fit(X,y, )\n",
    "poisson_log = PoissonGLM(link = sj.glm.log_link).fit(X,y)\n",
    "glm_gamma_new = GammaGLM().fit(X,y)\n",
    "inv_gauss = InverseNormalGLM().fit(X,y)\n",
    "inv_gauss2 = InverseNormalGLM(link = sj.glm.identity_link).fit(X,y)\n",
    "\n",
    "glm_table = sj.RegressionTable([nglm,poisson_id, poisson_log,glm_gamma_new,inv_gauss,inv_gauss2])\n",
    "glm_table.custom_columns([\"Normal\", \"Poisson (Identity)\", \"Poisson (Log)\", \"Gamma\", \"Inverse Gaussian\", \"Inverse Gaussian (Identity)\"])\n",
    "glm_table.title(\"Base GLMS\")\n",
    "glm_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GLM framework allows the definition of custom GLMs from a link function and distribution. The initial guess of parameters must have the correct shape since the GLM will not infer how many parameters or the shape of those parameters. The link function must have the form  $g: S\\to \\R$ where $S$ is the support of the model, and must be invertible by `oryx`. If it is not invertible, the user can specific a custom inverse: see the `oryx` documentation for more information. \n",
    "The first parameter of the specified distribution must be the mean of the distribution or whatever parameter is equal to $g^{-1} (\\mathbf X \\beta)$. \n",
    "\n",
    "By default, the model will use weighted least squares to fit the model. If this fails to train, `sj.glm.fit_glm_gradient` is a more robust alternative. However, it is sensitive to the initial guess of beta, unlike the least squares fitting procedure. \n",
    "\n",
    "Note that in the below demonstration, the least squares inverse gaussian model produces a slightly different result: with non-canonical link functions, the least squares and gradient-based algorithms do not necessarily converge to the same solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Poisson with inverse link and Inverse Gaussian with identity link GLM Comparison<br><table style=\"text-align:center\"><tr><td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(YES)</td><td>(YES)</td><td>(YES)</td><td>(YES)</td><td>(YES)</td><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">Custom Poisson</td><td colspan=\"1\">Poisson</td><td colspan=\"1\">Custom Inverse Gaussian: least squares</td><td colspan=\"1\">Custom Inverse Gaussian: gradient</td><td colspan=\"1\">Inverse Gaussian </td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td><td>(5)</td></tr>\n",
       "<tr><td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>-0.019<sup></sup></td><td>-0.019<sup></sup></td><td>113.638<sup>***</sup></td><td>114.002<sup>***</sup></td><td>114.002<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.025)</td><td>(0.025)</td><td>(35.800)</td><td>(35.794)</td><td>(35.794)</td></tr>\n",
       "<tr><td style=\"text-align:left\">COUTAX</td><td>5.03e-05<sup></sup></td><td>5.03e-05<sup></sup></td><td>-0.093<sup>*</sup></td><td>-0.094<sup>*</sup></td><td>-0.094<sup>*</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(3.52e-05)</td><td>(3.52e-05)</td><td>(0.050)</td><td>(0.050)</td><td>(0.050)</td></tr>\n",
       "<tr><td style=\"text-align:left\">UNEMPF</td><td>2.08e-03<sup>*</sup></td><td>2.08e-03<sup>*</sup></td><td>-4.331<sup>***</sup></td><td>-4.345<sup>***</sup></td><td>-4.345<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(1.17e-03)</td><td>(1.17e-03)</td><td>(1.545)</td><td>(1.544)</td><td>(1.544)</td></tr>\n",
       "<tr><td style=\"text-align:left\">MOR</td><td>-6.67e-05<sup></sup></td><td>-6.67e-05<sup></sup></td><td>0.327<sup>***</sup></td><td>0.327<sup>***</sup></td><td>0.327<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(5.79e-05)</td><td>(5.79e-05)</td><td>(0.084)</td><td>(0.084)</td><td>(0.084)</td></tr>\n",
       "<tr><td style=\"text-align:left\">ACT</td><td>1.14e-04<sup></sup></td><td>1.14e-04<sup></sup></td><td>-0.381<sup>**</sup></td><td>-0.382<sup>**</sup></td><td>-0.382<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(8.37e-05)</td><td>(8.37e-05)</td><td>(0.152)</td><td>(0.152)</td><td>(0.152)</td></tr>\n",
       "<tr><td style=\"text-align:left\">GDP</td><td>-1.43e-07<sup></sup></td><td>-1.43e-07<sup></sup></td><td>4.15e-04<sup></sup></td><td>4.15e-04<sup></sup></td><td>4.15e-04<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(2.68e-07)</td><td>(2.68e-07)</td><td>(3.50e-04)</td><td>(3.50e-04)</td><td>(3.50e-04)</td></tr>\n",
       "<tr><td style=\"text-align:left\">AGE</td><td>-5.33e-04<sup></sup></td><td>-5.33e-04<sup></sup></td><td>1.606<sup>**</sup></td><td>1.607<sup>**</sup></td><td>1.607<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(5.06e-04)</td><td>(5.06e-04)</td><td>(0.783)</td><td>(0.783)</td><td>(0.783)</td></tr>\n",
       "<tr><td style=\"text-align:left\">COUTAX_FEMALEUNEMP</td><td>-2.46e-06<sup></sup></td><td>-2.46e-06<sup></sup></td><td>4.86e-03<sup>**</sup></td><td>4.88e-03<sup>**</sup></td><td>4.88e-03<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(1.64e-06)</td><td>(1.64e-06)</td><td>(2.18e-03)</td><td>(2.18e-03)</td><td>(2.18e-03)</td></tr>\n",
       "\n",
       "<td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>32</td><td>32</td><td>32</td><td>32</td><td>32</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.845</td><td>0.845</td><td>0.838</td><td>0.838</td><td>0.838</td></tr><tr><td style=\"text-align: left\">AIC</td><td>211.558</td><td>211.558</td><td>182.654</td><td>182.654</td><td>182.654</td></tr><tr><td style=\"text-align: left\">BIC</td><td>223.283</td><td>223.283</td><td>194.380</td><td>194.380</td><td>194.380</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>15.639<sup>***</sup> (df=31; 25)</td><td>15.639<sup>***</sup> (df=31; 25)</td><td>14.841<sup>***</sup> (df=31; 25)</td><td>14.852<sup>***</sup> (df=31; 25)</td><td>14.852<sup>***</sup> (df=31; 25)</td></tr>\n",
       "<tr><td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"5\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x28b4a8ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.statjax.glm import GLM\n",
    "from oryx.distributions import Poisson, InverseGaussian\n",
    "import jax.numpy as jnp\n",
    "\n",
    "identity = lambda x: x\n",
    "custom_inverse = lambda x: 1/x\n",
    "\n",
    "custom_poisson = GLM(link = custom_inverse,\n",
    "                     dist = Poisson, \n",
    "                     params_init = (jnp.zeros([X.shape[1]+1] ) ),\n",
    "                    )\n",
    "\n",
    "custom_inverse_gaussian_1 = GLM(link = identity,\n",
    "                                dist = InverseGaussian,\n",
    "                                params_init = (jnp.zeros([X.shape[1]+1] )+ 1e-8 , jnp.ones(1)  ),\n",
    "                               )\n",
    "\n",
    "custom_inverse_gaussian_2 = GLM(link = identity,\n",
    "                              dist = InverseGaussian,\n",
    "                              params_init = (jnp.zeros([X.shape[1]+1] )+ 1e-8 , jnp.ones(1)  ),\n",
    "                              fit = sj.glm.fit_glm_gradient\n",
    "                             )\n",
    "\n",
    "custom_glm_table = sj.RegressionTable([custom_poisson.fit(X,y),\n",
    "                                    PoissonGLM(link = sj.glm.inverse_link).fit(X,y),\n",
    "                                    custom_inverse_gaussian_1.fit(X,y),\n",
    "                                    custom_inverse_gaussian_2.fit(X,y),\n",
    "                                    InverseNormalGLM(link = sj.glm.identity_link).fit(X,y)])\n",
    "\n",
    "custom_glm_table.custom_columns([\"Custom Poisson\", \"Poisson\", \"Custom Inverse Gaussian: least squares\", \"Custom Inverse Gaussian: gradient\", \"Inverse Gaussian \"])\n",
    "custom_glm_table.title_text = \"Poisson with inverse link and Inverse Gaussian with identity link GLM Comparison\"\n",
    "display(custom_glm_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BernoulliGLM class uses a logit link by default. To use a probit link instead, simply use the method from `statjax.glm`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuacy of logit and probit glms: (Array(0.91915643, dtype=float32), Array(0.9209139, dtype=float32))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(y)</td><td>(y)</td><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td></tr>\n",
       "<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>-1.077<sup></sup></td><td>-0.940<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(6.610)</td><td>(3.842)</td></tr>\n",
       "<tr><td style=\"text-align:left\">x0</td><td>0.254<sup>*</sup></td><td>0.156<sup>*</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.153)</td><td>(0.089)</td></tr>\n",
       "<tr><td style=\"text-align:left\">x1</td><td>-0.027<sup>**</sup></td><td>-0.016<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.012)</td><td>(6.90e-03)</td></tr>\n",
       "<tr><td style=\"text-align:left\">x2</td><td>-11.108<sup>*</sup></td><td>-6.249<sup>*</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(6.004)</td><td>(3.509)</td></tr>\n",
       "<tr><td style=\"text-align:left\">x3</td><td>-56.596<sup>***</sup></td><td>-33.884<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(20.259)</td><td>(11.781)</td></tr>\n",
       "<tr><td style=\"text-align:left\">x4</td><td>-8.672<sup></sup></td><td>-5.338<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(10.337)</td><td>(6.018)</td></tr>\n",
       "\n",
       "<td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>569</td><td>569</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.767</td><td>0.768</td></tr><tr><td style=\"text-align: left\">AIC</td><td>1212.528</td><td>369.807</td></tr><tr><td style=\"text-align: left\">BIC</td><td>1238.591</td><td>395.871</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>307.512<sup>***</sup> (df=568; 564)</td><td>309.835<sup>***</sup> (df=568; 564)</td></tr>\n",
       "<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"2\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x29481f650>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from statjax.glm import BernoulliGLM, probit_link\n",
    "\n",
    "import sklearn.datasets\n",
    "X2, y2 = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "X2= X2[:, [2,3,6,7,8]]\n",
    "\n",
    "logit_glm = BernoulliGLM().fit(X2,y2)\n",
    "probit_glm = BernoulliGLM(link = probit_link).fit(X2,y2)\n",
    "print(f\"accuacy of logit and probit glms: {((((logit_glm.predict(X2)) > .5) == y2).mean(), ((probit_glm.predict((X2)) > .5) == y2).mean())}\")\n",
    "sj.RegressionTable([logit_glm, probit_glm])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized and Gradient-Based Models\n",
    "\n",
    "The package also provides access to basic regularized models, as well as functionality for the user to define linear models according to a predict, loss, and regularization function. The user can define arbitrary NLMs by loss, predict, and regularization in a similar way to the GLMs above, but the models tend to be unstable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(target)</td><td>(target)</td><td>(target)</td><td>(target)</td><td>(target)</td><td>(target)</td><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">OLS</td><td colspan=\"1\">Normal GLM</td><td colspan=\"1\">ElasticNet</td><td colspan=\"1\">Ridge (Analytic)</td><td colspan=\"1\">Ridge (Gradient)</td><td colspan=\"1\">LASSO</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td><td>(5)</td><td>(6)</td></tr>\n",
       "<tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>152.133<sup>***</sup></td><td>152.133<sup>***</sup></td><td>123.972</td><td>124.065</td><td>124.065</td><td>152.020</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(2.576)</td><td>(2.544)</td><td></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">age</td><td>-10.010<sup></sup></td><td>-10.010<sup></sup></td><td>2.387</td><td>2.897</td><td>2.870</td><td>-7.16e-04</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(59.749)</td><td>(59.001)</td><td></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">sex</td><td>-239.816<sup>***</sup></td><td>-239.816<sup>***</sup></td><td>0.102</td><td>0.585</td><td>0.584</td><td>-136.830</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(61.222)</td><td>(60.456)</td><td></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">bmi</td><td>519.846<sup>***</sup></td><td>519.846<sup>***</sup></td><td>8.659</td><td>9.241</td><td>9.145</td><td>487.002</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(66.533)</td><td>(65.700)</td><td></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">bp</td><td>324.385<sup>***</sup></td><td>324.385<sup>***</sup></td><td>6.376</td><td>6.931</td><td>6.861</td><td>273.337</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(65.422)</td><td>(64.603)</td><td></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">s1</td><td>-792.176<sup>*</sup></td><td>-792.176<sup>*</sup></td><td>2.724</td><td>3.231</td><td>3.203</td><td>-6.964</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(416.680)</td><td>(411.462)</td><td></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">s2</td><td>476.739<sup></sup></td><td>476.739<sup></sup></td><td>2.119</td><td>2.617</td><td>2.596</td><td>-48.944</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(339.030)</td><td>(334.785)</td><td></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">s3</td><td>101.043<sup></sup></td><td>101.043<sup></sup></td><td>-5.630</td><td>-6.175</td><td>-6.113</td><td>-182.254</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(212.531)</td><td>(209.870)</td><td></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">s4</td><td>177.063<sup></sup></td><td>177.063<sup></sup></td><td>6.137</td><td>6.678</td><td>6.614</td><td>66.894</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(161.476)</td><td>(159.454)</td><td></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">s5</td><td>751.274<sup>***</sup></td><td>751.274<sup>***</sup></td><td>8.305</td><td>8.877</td><td>8.787</td><td>405.780</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(171.900)</td><td>(169.747)</td><td></td><td></td><td></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">s6</td><td>67.627<sup></sup></td><td>67.627<sup></sup></td><td>5.416</td><td>5.956</td><td>5.897</td><td>74.472</td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(65.984)</td><td>(65.158)</td><td></td><td></td><td></td><td></td></tr>\n",
       "\n",
       "<td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>442</td><td>442</td><td>442</td><td>442</td><td>442</td><td>442</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.518</td><td>0.518</td><td>-0.108</td><td>-0.105</td><td>-0.105</td><td>0.504</td></tr><tr><td style=\"text-align: left\">AIC</td><td></td><td>4793.986</td><td></td><td></td><td></td><td></td></tr><tr><td style=\"text-align: left\">BIC</td><td></td><td>4838.990</td><td></td><td></td><td></td><td></td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>41.968<sup>***</sup> (df=441; 432)</td><td>41.968<sup>***</sup> (df=441; 432)</td><td>-3.819<sup>***</sup> (df=441; 432)</td><td>-3.720<sup>***</sup> (df=441; 432)</td><td>-3.729<sup>***</sup> (df=441; 432)</td><td>39.775<sup>***</sup> (df=441; 432)</td></tr>\n",
       "<tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"6\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x299b9b3b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "from statjax.nlm import ElasticNet, LASSO\n",
    "from statjax import Ridge\n",
    "\n",
    "X,y = sklearn.datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
    "r = sj.RegressionTable([ sj.OLS().fit(X,y), NormalGLM().fit(X,y), ElasticNet(100,100).fit(X,y), Ridge(100).fit(X,y), ElasticNet(0,100).fit(X,y), LASSO(100).fit(X,y)])\n",
    "r.custom_columns([\"OLS\", \"Normal GLM\", \"ElasticNet\", \"Ridge (Analytic)\", \"Ridge (Gradient)\", \"LASSO\"])\n",
    "display(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's also a default neural network - more on that in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Models\n",
    "\n",
    "`statjax` currently offers four causal ate estimators. We'll first download the Lalonde dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:24: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:24: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/kq/xxx341651fg6vk0b96q6j7r00000gn/T/ipykernel_33517/1230381039.py:24: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  files = [pd.read_csv(file_name, sep='\\s+', header=None, names=columns) for file_name in file_names]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# https://users.nber.org/~rdehejia/nswdata2.html\n",
    "\n",
    "columns = [\"training\",   # Treatment assignment indicator\n",
    "           \"age\",        # Age of participant\n",
    "           \"education\",  # Years of education\n",
    "           \"black\",      # Indicate whether individual is black\n",
    "           \"hispanic\",   # Indicate whether individual is hispanic\n",
    "           \"married\",    # Indicate whether individual is married\n",
    "           \"no_degree\",  # Indicate if individual has no high-school diploma\n",
    "           \"re74\",       # Real earnings in 1974, prior to study participation\n",
    "           \"re75\",       # Real earnings in 1975, prior to study participation\n",
    "           \"re78\"]       # Real earnings in 1978, after study end\n",
    "\n",
    "\n",
    "file_names = [\"http://www.nber.org/~rdehejia/data/nswre74_treated.txt\",\n",
    "              \"http://www.nber.org/~rdehejia/data/nswre74_control.txt\",\n",
    "              \"http://www.nber.org/~rdehejia/data/psid_controls.txt\",\n",
    "              \"http://www.nber.org/~rdehejia/data/psid2_controls.txt\",\n",
    "              \"http://www.nber.org/~rdehejia/data/psid3_controls.txt\",\n",
    "              \"http://www.nber.org/~rdehejia/data/cps_controls.txt\",\n",
    "              \"http://www.nber.org/~rdehejia/data/cps2_controls.txt\",\n",
    "              \"http://www.nber.org/~rdehejia/data/cps3_controls.txt\"]\n",
    "files = [pd.read_csv(file_name, sep='\\s+', header=None, names=columns) for file_name in file_names]\n",
    "lalonde = pd.concat(files, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`statjax` follows the Rudin causal model, with $D$ indicating treatment status, $X$ indicating covariates, and $Y$ indicating outcomes. We remove points with features outside the range of that feature among the treated points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n violating overlap: 7407\n"
     ]
    }
   ],
   "source": [
    "from statjax import causal\n",
    "\n",
    "D = lalonde[[\"training\"]]\n",
    "X = lalonde[[\"age\", \"education\", \"black\", \"hispanic\", \"married\", \"no_degree\", \"re74\", \"re75\"]]\n",
    "Y = lalonde[[\"re78\"]]\n",
    "\n",
    "in_overlap = causal.check_overlap(D,lalonde[list(X.columns)])\n",
    "\n",
    "print(f\"n violating overlap: {sum(~in_overlap)}\")\n",
    "D = D[in_overlap]\n",
    "X = X[in_overlap]\n",
    "Y = Y[in_overlap]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ExperimentalEstimator class assumes random assignment, and simply compares the group means. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ols coef on treatment w/o controls: -6497.048111659512\n",
      "ols coef on treatment w/ controls: -107.58057145844275\n",
      "naive ate: -6497.048111659312\n"
     ]
    }
   ],
   "source": [
    "linreg = OLS().fit(D,Y)\n",
    "linreg_controlled = OLS().fit(jnp.hstack([X.values, D.values]),Y)\n",
    "print(f\"ols coef on treatment w/o controls: {linreg.beta[1]}\")\n",
    "print(f\"ols coef on treatment w/ controls: {linreg_controlled.beta[1]}\")\n",
    "\n",
    "naive_model = causal.ExperimentalEstimator().fit(D,Y)\n",
    "exp_est = naive_model.ate\n",
    "print(f\"naive ate: {exp_est}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RegressionEstimator fits two regression models, one for each treatment outcome, and compares the difference in expectation. It defaults to linear estimators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ols imputation ate: -2809.682457499978\n"
     ]
    }
   ],
   "source": [
    "regression_model = causal.RegressionEstimator().fit(D,X, Y)\n",
    "print(f\"ols imputation ate: {regression_model.ate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It allows for more other regression models. While it takes longer to train, here we use the NNRegression model, which is a flexible neural net that can be used as a miscellaneous non-parametric model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural imputation ate: 26136.701298586253\n"
     ]
    }
   ],
   "source": [
    "from statjax.nn import NNRegression\n",
    "\n",
    "nn_regression_model =  causal.RegressionEstimator(model=NNRegression(hidden_layers = (128,128,64,64)))\n",
    "nn_regression_model.fit(D,X,Y)\n",
    "print(f\"neural imputation ate: {nn_regression_model.ate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PropensityScoreEstimator fits $p(D_i=1|X_i)$  then uses that as inverse weights. The default model is a logistic regression, but the user can specify alternatives.\n",
    "\n",
    "Note that the model automatically prunes points with $p>1-\\delta$ or $p<\\delta$, with the default at initialization as $\\delta = .1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit ate: 2186.539131282006, probit ate: 2571.336146299483, nn ate: 1320.169593785673\n"
     ]
    }
   ],
   "source": [
    "from jax.nn import sigmoid\n",
    "\n",
    "logit_model = causal.PropensityScoreEstimator().fit(D,X,Y)\n",
    "probit_model = causal.PropensityScoreEstimator(propensity_model=BernoulliGLM(link=probit_link)).fit(D,X,Y)\n",
    "\n",
    "nn_ps_model = causal.PropensityScoreEstimator(propensity_model=NNRegression(hidden_layers = (32,32),output_activation=sigmoid)).fit(D,X,Y)\n",
    "\n",
    "print(f\"logit ate: {logit_model.ate}, probit ate: {probit_model.ate}, nn ate: {nn_ps_model.ate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, `statjax` contains a doubly robust estimator, which can take a custom propensity_model and outcome_model. To demonstrate why pruning is important, we can fit a DRE without any pruning ($\\delta = 0$) to see the effect on the ATE.  \n",
    "\n",
    "As above, the bulk of the runtime is the outcome network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dre ate: 2084.2925401808584\n",
      "neural propensity dre ate: 1137.4334587308513\n",
      "fully neural dre ate: 2421.439895598937\n",
      "unpruned dre ate: 12717764449.22189\n"
     ]
    }
   ],
   "source": [
    "from statjax.causal import DREstimator\n",
    "    \n",
    "dre_model = DREstimator().fit(D,X,Y)\n",
    "dre_model_unpruned = DREstimator(delta = 0.).fit(D,X,Y)\n",
    "\n",
    "neural_dre = DREstimator(propensity_model=NNRegression(hidden_layers = (32,32),output_activation=sigmoid)).fit(D,X,Y)\n",
    "fully_neural_dre = DREstimator(outcome_model=NNRegression(hidden_layers=(128, 128, 64, 64)),\n",
    "                              propensity_model=NNRegression(hidden_layers = (32,32),output_activation=sigmoid),\n",
    "                              ).fit(D,X,Y)\n",
    "\n",
    "print(f\"dre ate: {dre_model.ate}\\nneural propensity dre ate: {neural_dre.ate}\\nfully neural dre ate: {fully_neural_dre.ate}\\nunpruned dre ate: {dre_model_unpruned.ate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submodels of any causal model can be accessed at model0/model1 for regression-based models and propensity_model for propensity scoring models. Here are all 3 from the DRE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(training)</td><td>(re78)</td><td>(re78)</td><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">P(D=1|X)</td><td colspan=\"1\">E[Y|X,D=0]</td><td colspan=\"1\">E[Y|X,D=1]</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>-4.183<sup>**</sup></td><td>4361.918<sup>***</sup></td><td>-1508.424<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(1.669)</td><td>(599.002)</td><td>(6006.589)</td></tr>\n",
       "<tr><td style=\"text-align:left\">age</td><td>0.023<sup></sup></td><td>-110.543<sup>***</sup></td><td>83.562<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.016)</td><td>(8.069)</td><td>(85.387)</td></tr>\n",
       "<tr><td style=\"text-align:left\">education</td><td>-0.069<sup></sup></td><td>280.199<sup>***</sup></td><td>623.961<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.083)</td><td>(40.582)</td><td>(395.287)</td></tr>\n",
       "<tr><td style=\"text-align:left\">black</td><td>3.007<sup>**</sup></td><td>-950.709<sup>***</sup></td><td>-1140.014<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(1.181)</td><td>(179.060)</td><td>(1981.176)</td></tr>\n",
       "<tr><td style=\"text-align:left\">hispanic</td><td>1.270<sup></sup></td><td>-182.150<sup></sup></td><td>304.327<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(1.479)</td><td>(232.658)</td><td>(3057.645)</td></tr>\n",
       "<tr><td style=\"text-align:left\">married</td><td>-0.914<sup>**</sup></td><td>211.242<sup></sup></td><td>1032.440<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.432)</td><td>(148.457)</td><td>(1589.880)</td></tr>\n",
       "<tr><td style=\"text-align:left\">no_degree</td><td>0.142<sup></sup></td><td>370.443<sup>*</sup></td><td>-319.009<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.403)</td><td>(197.691)</td><td>(1807.132)</td></tr>\n",
       "<tr><td style=\"text-align:left\">re74</td><td>-5.67e-04<sup>**</sup></td><td>0.318<sup>***</sup></td><td>0.039<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(2.61e-04)</td><td>(0.012)</td><td>(0.160)</td></tr>\n",
       "<tr><td style=\"text-align:left\">re75</td><td>-3.12e-05<sup></sup></td><td>0.469<sup>***</sup></td><td>0.089<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(8.72e-05)</td><td>(0.013)</td><td>(0.244)</td></tr>\n",
       "\n",
       "<td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>14699</td><td>14514</td><td>185</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.130</td><td>0.414</td><td>0.050</td></tr><tr><td style=\"text-align: left\">AIC</td><td>6833.652</td><td></td><td></td></tr><tr><td style=\"text-align: left\">BIC</td><td>6902.012</td><td></td><td></td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>243.112<sup>***</sup> (df=14698; 14691)</td><td>1136.882<sup>***</sup> (df=14513; 14506)</td><td>1.023<sup></sup> (df=184; 177)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"3\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<statjax.tables.RegressionTable at 0x2bd1730b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dre_table = sj.RegressionTable([dre_model.propensity_model, dre_model.model0, dre_model.model1])\n",
    "dre_table.custom_columns([\"P(D=1|X)\", \"E[Y|X,D=0]\", \"E[Y|X,D=1]\"])\n",
    "dre_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Personal (3.12)",
   "language": "python",
   "name": "personal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
